{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75322484",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining Measurement Matrices ##\n",
    "\n",
    "def gaussian_mx(m,N):\n",
    "    A = np.random.normal(0.0, 1.0, [m, N])\n",
    "    return A\n",
    "\n",
    "def hadamard_mx(m,N):\n",
    "    A = hadamard(N)\n",
    "    l = permutation(np.range(N))\n",
    "    return A[l[:m],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e91dab93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_tl(X): ##Vectorisation for tensors\n",
    "    x=X.numpy()\n",
    "    x=x.reshape(-1)\n",
    "    return x\n",
    "\n",
    "def vectorize_np(X):  ##Vecorisation for numpy arrays\n",
    "    x=X\n",
    "    x=x.reshape(-1)\n",
    "    return x\n",
    "\n",
    "def row_normalised_mx(A,b,n_dim):\n",
    "    B = np.zeros(np.shape(A))\n",
    "    c = np.zeros(np.shape(b))\n",
    "    for i in range(np.shape(A)[0]):\n",
    "        B[i,:] = np.sqrt(n_dim)*A[i,:]/np.linalg.norm(A[i,:])\n",
    "        c[i] = np.sqrt(n_dim)*b[i]/np.linalg.norm(A[i,:])\n",
    "    return B,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f34e7020",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Thresholding operators #########\n",
    "\n",
    "def random_low_rank_HOSVD(n,r,eps = 0.1):\n",
    "    C=np.random.normal(0,1,size=r)+eps\n",
    "    C=tl.tensor(C)\n",
    "    #C.shape\n",
    "    X=C ##core tensor\n",
    "\n",
    "    U=[]\n",
    "    for i in range(len(n)):\n",
    "        M=np.random.normal(0,1,size=(n[i],n[i]))+eps\n",
    "        u,sigma,v=np.linalg.svd(M)\n",
    "        U.append(u[:,0:r[i]])\n",
    "\n",
    "    for i in range(len(n)):\n",
    "        X=tl.tenalg.mode_dot(X,U[i],i)\n",
    "    return X\n",
    "\n",
    "def random_lowrank_HOSVD_tensor(n,r,eps = 2):\n",
    "    C=np.random.normal(0,1,size=r)+eps*np.random.uniform(0,1,size=r)\n",
    "    C=tl.tensor(C)\n",
    "    #C.shape\n",
    "    X=C ##core tensor\n",
    "\n",
    "    U=[]\n",
    "    for i in range(len(n)):\n",
    "        M=np.random.normal(0,1,size=(n[i],n[i]))+eps\n",
    "        u,sigma,v=np.linalg.svd(M)\n",
    "        U.append(u[:,0:r[i]])\n",
    "\n",
    "    for i in range(len(n)):\n",
    "        X=tl.tenalg.mode_dot(X,U[i],i)\n",
    "    return X\n",
    "\n",
    "\n",
    "def random_low_rank_CP(n,r,eps = 0.1):   #### CP Rank r\n",
    "    \n",
    "    L = []\n",
    "    for i in range(0,len(n)):\n",
    "        C=np.random.normal(0,1,size=(n[i],r))+eps\n",
    "        L = L + [C]\n",
    "    \n",
    "    X = np.zeros(n)\n",
    "    for i in range(r):\n",
    "        U_r = np.array(L[0])[:,i]\n",
    "        for j in range(1, len(n)):\n",
    "            prod = np.array(L[j])[:,i]\n",
    "            U_r = np.multiply.outer(U_r,prod)\n",
    "        X = X + U_r\n",
    "        \n",
    "    C=tl.tensor(X) #Changing data frame to tensor\n",
    "    C.shape\n",
    "    return C\n",
    "\n",
    "def HOSVD_rank_app(tensor,r): ## HOSVD rank-r approximation\n",
    "    \n",
    "    core, factors = tl.decomposition.tucker(tensor.numpy(), r) #Decomposition function is used \n",
    "    answer = torch.tensor(tl.tucker_to_tensor([core, factors]))\n",
    "    \n",
    "    return answer\n",
    "\n",
    "def CP_rank_app(tensor,r):  ## CP rank-r approximation\n",
    "    \n",
    "    factors = parafac(tl.tensor(tensor), rank=r)\n",
    "    answer = tl.cp_to_tensor(factors)\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edea29d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TIHT_CP(AA,yy,X,r,lamda = 1, itr = 100): \n",
    "    \n",
    "    n = np.shape(X)\n",
    "    X_ravel = np.ravel(X)\n",
    "    \n",
    "    error = np.zeros(itr)\n",
    "    \n",
    "    vXX = torch.randn(n)*0 \n",
    "    converge = True\n",
    "    j = 0\n",
    "            \n",
    "    while converge == True and j < itr:\n",
    "        try:\n",
    "            WW = np.array(vectorize_np(vXX)) + lamda*np.matmul(AA.T, (yy - np.matmul(AA, np.array(vectorize_np(vXX)))))\n",
    "            WW = torch.reshape(torch.tensor(WW), n)\n",
    "            vXX = CP_rank_app(WW,r)\n",
    "            error[j] = np.linalg.norm(vectorize_np(vXX)- X_ravel)/np.linalg.norm(X_ravel)\n",
    "            j = j+1\n",
    "        \n",
    "        except np.linalg.LinAlgError:\n",
    "            print(\"Doesn't converge\")\n",
    "            y = np.zeros(np.shape(X_ravel)[0])-1\n",
    "            error = np.zeros(itr)+np.inf\n",
    "            converge = False\n",
    "        \n",
    "    return vXX, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfb28f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TIHT_HOSVD(AA,yy,X,r,lamda = 1, itr = 100, threshold=True): \n",
    "    \n",
    "    n = np.shape(X)\n",
    "    X_ravel = np.ravel(X)\n",
    "    \n",
    "    error = np.zeros(itr)\n",
    "    \n",
    "    vXX = torch.randn(n)*0\n",
    "    converge = True\n",
    "    k = 0\n",
    "            \n",
    "    while converge == True and k < itr:\n",
    "        try:\n",
    "                WW = np.array(vectorize_tl(vXX)) + lamda* np.matmul(AA.T, (yy - np.matmul(AA, np.array(vectorize_tl(vXX)))))\n",
    "                WW = torch.reshape(torch.tensor(WW), n)\n",
    "                vXX = HOSVD_rank_app(WW,r)\n",
    "                error[k] = np.linalg.norm(vectorize_tl(vXX)- X_ravel)/np.linalg.norm(X_ravel)    \n",
    "                k = k+1 \n",
    "                \n",
    "        except np.linalg.LinAlgError:\n",
    "            print(\"Doesn't converge\")\n",
    "            y = np.zeros(np.shape(X_ravel)[0])-1\n",
    "            error = np.zeros(itr)+np.inf\n",
    "            converge = False\n",
    "  \n",
    "    return vXX, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12856cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KZIHT_RR(A,b,x,s,gamma=1,itr=100): ## Selecting rows with replacement, gamma-step size for Kaczmarz\n",
    "    \n",
    "    error = np.zeros(itr)\n",
    "    m = np.shape(A)[0]\n",
    "    y= np.zeros(np.shape(x)[0])\n",
    "    \n",
    "    for k in range(itr): # Outer iteration for IHT updates\n",
    "        \n",
    "        t = permutation(np.arange(m))\n",
    "        \n",
    "        for j in range(m): #Inner iteration for Kaczmarz updates\n",
    "            \n",
    "            a = A[t[j],:]\n",
    "            y = y + gamma*(b[t[j]] - a@y)*a/(np.linalg.norm(a)**2)\n",
    "                           \n",
    "        y = sparse_vect(y,s)\n",
    "        error[k] = np.linalg.norm(y-x)/np.linalg.norm(x)\n",
    "        \n",
    "    return y,error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14993a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KZIHT_HOSVD_RR(A,b,X,n,r,gamma = 1, lamda = 1, itr = 100):\n",
    "    \n",
    "    error = np.zeros(itr)\n",
    "    m = np.shape(A)[0]\n",
    "    n_dim =  np.shape(A)[1]\n",
    "    \n",
    "    n = np.shape(X)\n",
    "    x = np.ravel(X)\n",
    "    \n",
    "    A,b = row_normalised_mx(A,b,n_dim)\n",
    "    \n",
    "    y = np.zeros(np.shape(x)[0]) \n",
    "    converge = True\n",
    "    k = 0\n",
    "    \n",
    "    gamma = gamma*n_dim/m\n",
    "            \n",
    "    while converge == True and k < itr:\n",
    "        y_old = y\n",
    "        try:\n",
    "            t = permutation(np.arange(m))\n",
    "            for j in range(m): #Inner iteration for Kaczmarz updates\n",
    "                a = A[t[j],:]\n",
    "                y = y + gamma*(b[t[j]] - a@y)*a/(np.linalg.norm(a)**2)    \n",
    "            y = y_old + lamda*(y - y_old)   \n",
    "            WW = torch.reshape(torch.tensor(y), n)\n",
    "            y = vectorize_tl(HOSVD_rank_app(WW,r))\n",
    "            error[k] = np.linalg.norm(vectorize_np(y)-x)/np.linalg.norm(x)\n",
    "            k = k+1 \n",
    "                \n",
    "        except np.linalg.LinAlgError:\n",
    "            print(\"Doesn't converge\")\n",
    "            y = np.zeros(np.shape(x)[0])-1\n",
    "            error = np.zeros(itr)+np.inf\n",
    "            converge = False\n",
    "                             \n",
    "    return y,error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "960b42e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KZIHT_CP_RR(A,b,X,n,r,gamma = 1,lamda = 1, itr = 100):\n",
    "    \n",
    "    error = np.zeros(itr)\n",
    "    m = np.shape(A)[0]\n",
    "    n_dim =  np.shape(A)[1]\n",
    "    \n",
    "    n = np.shape(X)\n",
    "    x = np.ravel(X)\n",
    "    A,b = row_normalised_mx(A,b,n_dim)\n",
    "    \n",
    "    y = np.zeros(np.shape(x)[0])    \n",
    "    converge = True\n",
    "    k = 0\n",
    "    \n",
    "    gamma = gamma*n_dim/m\n",
    "            \n",
    "    while converge == True and k < itr:\n",
    "        try:\n",
    "            y_old = y\n",
    "            t = permutation(np.arange(m))\n",
    "            for j in range(m): #Inner iteration for Kaczmarz updates\n",
    "                a = A[t[j],:]\n",
    "                y = y + gamma*(b[t[j]] - a@y)*a/(np.linalg.norm(a)**2)     \n",
    "                \n",
    "            y = y_old + lamda*(y - y_old)\n",
    "            WW = torch.reshape(torch.tensor(y), n)\n",
    "            y = CP_rank_app(WW,r)\n",
    "            error[k] = np.linalg.norm(vectorize_np(y)-x)/np.linalg.norm(x)\n",
    "            y = vectorize_np(y)\n",
    "            k = k+1 \n",
    "                             \n",
    "        except np.linalg.LinAlgError:\n",
    "            print(\"Doesn't converge\")\n",
    "            y = np.zeros(np.shape(x)[0])-1\n",
    "            error = np.zeros(itr)+np.inf\n",
    "            converge = False\n",
    "            \n",
    "    return y,error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3b6afe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KZPT_HOSVD_RR(A,b,X,n,r, period = 1,gamma = 1, lamda = 1, itr = 100):\n",
    "    \n",
    "    error = np.zeros(itr)\n",
    "    m = np.shape(A)[0]\n",
    "    n_dim =  np.shape(A)[1]\n",
    "    \n",
    "    n = np.shape(X)\n",
    "    x = np.ravel(X)\n",
    "    A,b = row_normalised_mx(A,b,n_dim)\n",
    "    \n",
    "    y = np.zeros(np.shape(x)[0])    \n",
    "    converge = True\n",
    "    k = 0\n",
    "    \n",
    "    gamma = gamma*n_dim/m\n",
    "            \n",
    "    while converge == True and k < itr:\n",
    "        try:\n",
    "            t = permutation(np.arange(m))\n",
    "            for j in range(m): #Inner iteration for Kaczmarz updates\n",
    "                y_old = y\n",
    "                a = A[t[j],:]\n",
    "                y = y + gamma*(b[t[j]] - a@y)*a/(np.linalg.norm(a)**2)\n",
    "                \n",
    "                if (j+1)%period == 0:\n",
    "                    y = y_old + lamda*(y - y_old)\n",
    "                    WW = torch.reshape(torch.tensor(y), n)\n",
    "                    y = vectorize_tl(HOSVD_rank_app(WW,r))\n",
    "                    \n",
    "            error[k] = np.linalg.norm(vectorize_np(y)-x)/np.linalg.norm(x)\n",
    "            k = k+1 \n",
    "                \n",
    "        except np.linalg.LinAlgError:\n",
    "            print(\"Doesn't converge\")\n",
    "            y = np.zeros(np.shape(x)[0])-1\n",
    "            error = np.zeros(itr)+np.inf\n",
    "            converge = False\n",
    "    return y,error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
